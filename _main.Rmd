---
title: "Cortes Transversales"
subtitle: " Curso Avanzado de Microeconometría Aplicada"
author: "Ana María Díaz"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
output:
  bookdown::gitbook:
    css: style.css
    split_by: chapter
---


knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(kableExtra)
library(tibble)


# Programa {-}

Este curso pretende que el estudiante obtenga un conocimiento básico de los métodos econométricos de corte transversal. El estudiante aprenderá las principales técnicas y metodologías econométricas para realizar inferencia causal, útiles para evaluar programas y políticas públicas o analizar problemas económicos complejos.

También se busca familiarizar a los estudiantes con herramientas computacionales. Se utilizará el paquete estadístico **Stata**, y se realizará un proyecto de investigación empleando al menos dos técnicas aprendidas en el curso.

## Información general {-}

- **Docente:** Ana María Díaz  
- **Correo:** a.diaze@javeriana.edu.co  
- **Oficina:** Séptimo Piso Edificio 20  
- **Atención:** Lunes 9–11am (con cita previa o por Teams)  
- **Página web:** [adiazescobar.com](http://adiazescobar.com)

- **Días de clase:** Martes y Jueves  
- **Horario:** 7–9 am  
- **Lugar:** Por definir  
- **Monitoría:** Por definir  

## Requisitos {-}

- Econometría Avanzada

## Evaluación {-}

| Componente           | Porcentaje |
|----------------------|------------|
| Parcial 1            | 25%        |
| Parcial 2            | 25%        |
| Examen Final         | 25%        |
| Talleres de Clase    | 10%        |
| Trabajo Final        | 15%        |

**Trabajo Final:**
- Primera entrega: 10% (Presentación de la idea)
- Segunda entrega: 20% (Introducción + Descriptiva + Metodología)
- Documento final: 30%
- Sustentación: 40%

## Bibliografía {-}

### Libros Obligatorios {-}

- Cunningham, Scott (2020). *Causal Inference: The Mixtape*. [Enlace](http://scunning.com/cunningham_mixtape.pdf)
- Bernal, R. y Peña, X. (2011). *Guía Práctica para la Evaluación de Impacto*. Universidad de los Andes.

### Libros Recomendados {-}

1. Wooldridge (2002). *Econometric Analysis of Cross Section and Panel Data*. MIT Press.  
2. Angrist & Pischke (2009). *Mostly Harmless Econometrics*. Princeton.  
3. Cameron & Trivedi (2009). *Microeconometrics Using Stata*.  
4. Baker (2000). *Evaluating the Impact of Development Projects on Poverty*. World Bank.  
5. Heckman et al. (2000). *The Economics and Econometrics of Active Labor Market Programs*.  

## Inclusión {-}

Este curso da la bienvenida a personas de todas las edades, géneros, orientaciones, etnias, creencias y capacidades. Se espera un ambiente respetuoso, acogedor e inclusivo.

## Integridad Académica {-}

No se permite el uso de inteligencia artificial, internet o ayudas externas en evaluaciones. El incumplimiento será sancionado conforme al reglamento de la Universidad.

## Programa del Curso {-}

A continuación se presenta el programa semanal del curso, organizado por módulo.
```{r programa_tabla, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(kableExtra)
library(tibble)

# Crear tabla
programa <- tribble(
  ~Semana, ~Módulo, ~Temas, ~Lecturas,

  "1", "1: Introducción a la Inferencia Causal", 
  "• Inferencia causal  
   • Contrafactual  
   • Parámetros de impacto",
  "Bernal y Peña (2011), Cap. 2-3  
   Heckman (2008)  
   Angrist y Pischke",

  "2", "1: Introducción a la Inferencia Causal", 
  "• Sesgo de selección", 
  "Angrist & Krueger (2000)",

  "3", "2: Métodos Experimentales", 
  "• Aleatorización  
   • Contrafactual  
   • Sesgo de selección",
  "Bernal y Peña (2011), Cap. 4  
   Duflo et al. (2008)  
   Heckman et al. (1997)",

  "4", "2: Métodos Experimentales", 
  "• Impacto con aleatorización  
   • Poder estadístico  
   • Problemas de aleatorización",
  "Duflo et al. (2008)",

  "5", "3: Métodos Cuasi-Experimentales", 
  "• Regresión lineal  
   • Supuestos de independencia condicional  
   • Variable dependiente binaria",
  "Angrist y Pischke (2009), Cap. 3  
   Cameron & Trivedi (2005), Cap. 14  
   Heckman (1990)",

  "6-7", "4: Diferencias en Diferencias y Panel", 
  "• DID simple y de panel  
   • Efectos fijos  
   • Heterogeneidad en DID", 
  "Gertler et al. (2010), Cap. 6  
   Bertrand et al. (2004)",

  "8", "4: Diferencias en Diferencias y Panel", 
  "• Efectos fijos y aleatorios  
   • Ventajas y desventajas del panel", 
  "Bernal y Peña (2011), Cap. 5  
   Angrist y Pischke (2009)",

  "9", "5: Propensity Score Matching", 
  "• Estimación del PS  
   • Balanceo  
   • Soporte común",
  "Bernal y Peña (2011), Cap. 6  
   Caliendo & Kopeining (2008)",

  "10", "5: Propensity Score Matching", 
  "• Algoritmos de emparejamiento  
   • Errores estándar  
   • Falsificación",
  "Bernal y Peña (2011), Cap. 6  
   Caliendo & Kopeining (2008)",

  "11", "6: Variables Instrumentales", 
  "• Definición de IV  
   • LATE  
   • Estimación con variables continuas", 
  "Angrist y Pischke (2009), Cap. 4  
   Gertler et al. (2010), Cap. 7  
   Bernal y Peña (2011), Cap. 7",

  "12", "6: Variables Instrumentales", 
  "• IV con variables discretas  
   • PSM con IV  
   • Problemas del IV", 
  "Khandker et al. (2010), Cap. 6-7",

  "13", "7: Regresión Discontinua", 
  "• RDD lineal  
   • RDD no paramétrica  
   • Sharp y Fuzzy RDD",
  "Gertler et al. (2010), Cap. 5  
   Bernal y Peña (2011), Cap. 8",

  "14", "8: Varios", 
  "• Función de control  
   • Machine Learning",
  "Bernal y Peña (2011), Cap. 9-10"
)

# Mostrar tabla bonita
programa %>%
  kbl(booktabs = TRUE, escape = FALSE, align = "c",
      caption = "Programa del curso de microeconometría aplicada") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = FALSE, position = "center") %>%
  row_spec(0, bold = TRUE, color = "white", background = "#1F77B4") %>%
  column_spec(1, bold = TRUE, color = "#444") %>%
  column_spec(2, bold = TRUE, color = "#444", background = "#EAEAF2") %>%
  column_spec(3, width = "20em") %>%
  column_spec(4, width = "20em")
```


```{r eval=FALSE}
bookdown::serve_book()
```


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# Análisis de Secciones Transversales


## Motivación para el análisis causal {-}

En su breve y sugerente cuento Del rigor en la ciencia, Jorge Luis Borges relata la historia de un imperio en el que los cartógrafos llevaron su arte a un grado de perfección tal, que terminaron por construir un mapa a escala 1:1, tan extenso y detallado como el mismo territorio que pretendía representar. Con el tiempo, ese mapa fue olvidado, y sus ruinas todavía se confunden con las del imperio.

> En aquel Imperio, el Arte de la Cartografía logró tal Perfección que el mapa de una sola Provincia ocupaba toda una Ciudad, y el mapa del Imperio, toda una Provincia. Con el tiempo, estos Mapas Desmesurados no satisficieron y los Colegios de Cartógrafos levantaron un Mapa del Imperio, que tenía el tamaño del Imperio y coincidía puntualmente con él. 
Menos Adictas al Estudio de la Cartografía, las Generaciones Siguientes entendieron que ese dilatado Mapa era Inútil y no sin Impiedad lo entregaron a las Inclemencias del Sol y los Inviernos. En los desiertos del Oeste perduran despedazadas Ruinas del Mapa, habitadas por Animales y por Mendigos; en todo el País no hay otra reliquia de las Disciplinas Geográficas.
(Suárez Miranda, Viajes de Varones Prudentes, Libro Cuarto, Cap. XLV, Lérida, 1658.)
FIN

Sabemos que no podemos capturar la complejidad del mundo en un solo modelo, pero aspiramos a representarlo con la suficiente precisión como para *entenderlo, intervenirlo y mejorarlo*. 

En este sentido, la econometría aplicada moderna se centra en la identificación de relaciones causales. Estas relaciones son fundamentales para comprender cómo funciona el mundo social, y para guiar decisiones informadas en el diseño de políticas públicas.

Como explican Angrist y Pischke en su libro *Mostly Harmless Econometrics*:

> En primer lugar, creemos que la investigación empírica es más valiosa cuando utiliza datos para responder preguntas causales específicas, *como si* se tratara de un ensayo clínico aleatorizado. Esta perspectiva moldea nuestro enfoque hacia la mayoría de las preguntas de investigación. En ausencia de un experimento real, buscamos comparaciones bien controladas y/o cuasiexperimentos naturales. Por supuesto, algunos diseños de investigación cuasiexperimentales son más convincentes que otros, pero .purple[los métodos econométricos utilizados en estos estudios suelen ser bastante simples].
*Mostly Harmless Econometrics*, p. xii 


## Motivación para el análisis causal - ¿Por qué es importante? {-}

¿Cómo lo entendemos? Sin duda, la identficación de relaciones causales es fundamental para entender cómo funcionan las cosas. 
Enteder la consecuencia de una acción es crucial para entender el mundo que nos rodea. 

Aquí es donde la teoría económica juega un papel central: nos proporciona un marco para interpretar esas relaciones causales, al tiempo que orienta nuestra atención hacia posibles mecanismos. Hacer econometría sin una teoría económica sólida, sin una teoría del cambio ni un esfuerzo por establecer mecanismos, es simplemente machacar datos. 

¿Cómo lo intervenimos? Las relaciones causales nos permiten hacer predicciones sobre el impacto de intervenciones y políticas. Por ejemplo, si sabemos que aumentar la educación de los niños mejora sus ingresos futuros, podemos diseñar políticas educativas que maximicen ese efecto. Sin esta información, el diseño de políticas se convierte en un ejercicio de ensayo y error, muchas veces costoso e ineficaz.

¿Cómo mejoramos? El análisis causal nos permite decir con cierta confianza qué cosas funcionan y bajo qué condiciones. Esto hace posible ajustar intervenciones para maximizar su impacto positivo. Por ejemplo, si sabemos que las transferencias monetarias condicionadas a la asistencia escolar aumentan la matrícula, podemos adaptar ese diseño a otros contextos y poblaciones.

Por esta razón, ha ganado fuerza el enfoque de políticas basadas en evidencia, que busca reemplazar la intuición, la tradición o la ideología con análisis rigurosos del mundo real. La microeconometría aplicada, con su atención al detalle y su vocación por la causalidad, es una herramienta clave en esa transición.

## Microeconometría y política pública {-}

La microeconometría aplicada es una herramienta fundamental para informar y mejorar la formulación de políticas públicas. Sus aportes se pueden clasificar en dos tipos:

**Efectos directos**
Asignación eficiente de recursos: permite identificar qué intervenciones generan mayor impacto por peso invertido.
Mejora de la calidad, eficiencia y efectividad de programas e instituciones.
Focalización en resultados, más allá de insumos o procesos.
Identificación de efectos no previstos, tanto positivos como negativos.
Fortalecimiento de la rendición de cuentas, mediante evaluaciones transparentes.
Efectos indirectos
Alimentar el debate público con evidencia rigurosa que permita contrastar discursos, creencias y enfoques ideológicos.

## Microeconometría y teoría económica {-}

Además de su valor instrumental, la microeconometría contribuye activamente al desarrollo y evaluación de la teoría económica. Entre sus aportes están:

Generar mejor y más información empírica, útil para contrastar modelos.
Reducir el ruido, eliminando hipótesis o mecanismos irrelevantes.
Guiar el diseño de nuevas políticas y experimentos, a partir de evidencia acumulada.
Promover discusiones más transparentes sobre los supuestos, facilitando la crítica constructiva.
Estimular la retroalimentación entre teoría, datos y política.

### Ejemplo exitoso: Progresa (Oportunidades, México, 1990) {-}

Uno de los programas más influyentes y mejor evaluados en América Latina es Progresa, posteriormente conocido como Oportunidades y luego Prospera. Lanzado en México en 1997, su diseño se basó en evidencia empírica y principios de incentivos económicos.

#### 🎯 Objetivo
Reducir la pobreza y mejorar el capital humano de los hogares más vulnerables, especialmente en áreas rurales. Para eso se bridó a los hogares pobres
-un ingreso monetario de corto plazo
-incentivos para invertir en capital humano, especialmente en la educación y salud infantil.
-Mecanismo_ Las transferencias estaban condicionadas a la asistencia escolar de los niños y a visitas regulares a centros de salud.

#### Resultados iniciales (2001) {-}

Las evaluaciones experimentales y cuasiexperimentales del programa mostraron efectos significativos:

Shultz (2004): aumento promedio de 0.7 años de escolaridad.
Gertler (2001): reducción del 23% en incidencia de enfermedades.
El programa mostró una focalización efectiva, beneficiando principalmente a los hogares más pobres.


```{r, echo=FALSE, out.width="80%"}
knitr::include_graphics("img/pegado2.png")
knitr::include_graphics("img/pegado1.png")
```

## Formulando una buena pregunta causal {-}

Más allá de definir la estrategia empírica, una investigación de calidad comienza por formular preguntas bien planteadas. En el enfoque de Angrist y Pischke, el punto de partida consiste en identificar claramente cuál es la **relación causal de interés**. Esta pregunta guía no solo el análisis, sino también la forma en que interpretamos los resultados y diseñamos la estrategia de identificación. Si no es posible formular de forma precisa y concisa qué efecto queremos estimar, es probable que aún no tengamos un verdadero proyecto de investigación.

Esto no implica que las descripciones sean inútiles: al contrario, los ejercicios descriptivos pueden ser valiosos e incluso necesarios. Pero en la econometría aplicada moderna, la causalidad ocupa un lugar central. Estimar relaciones causales permite poner a prueba directamente teorías sobre cómo funciona el mundo. Además, nos da acceso a contrafactuales, es decir, a estimaciones de qué habría pasado en ausencia de la intervención o del tratamiento.

Para ilustrarlo, pensemos en preguntas clásicas de la literatura:

- ¿Cómo afecta un año adicional de educación al salario?  
- ¿Qué impacto tienen las instituciones democráticas sobre el desarrollo económico?  
- ¿Los hogares pobres se benefician de la limpieza del medio ambiente?  
- ¿Las leyes de control de armas reducen efectivamente la violencia?

Todas estas preguntas comparten una estructura causal: comparan una situación observable con un contrafactual no observado. Y todas ellas podrían, en principio, ser abordadas mediante un diseño experimental o cuasiexperimental adecuado.

## El experimento ideal {-}

Una herramienta útil para clarificar la lógica causal de una investigación es imaginar el **experimento ideal**: aquel que asignaría aleatoriamente la causa de interés —educación, democracia, limpieza ambiental, leyes de armas— y luego compararía los resultados. Aunque muchas veces este experimento es hipotético o inviable, su formulación nos obliga a pensar con precisión: ¿qué grupo recibiría el tratamiento?, ¿qué factores deberíamos mantener constantes?, ¿cómo mediríamos el efecto?

Cuando no es posible siquiera imaginar cómo sería un experimento ideal, puede que estemos enfrentando lo que Angrist y Pischke denominan *preguntas fundamentalmente sin respuesta*. Por ejemplo, preguntas como “¿Qué efecto tiene el género sobre las trayectorias laborales futuras?” o “¿Qué rol juega la raza en los ingresos?” plantean desafíos éticos, conceptuales y metodológicos difíciles de sortear.

En cambio, hay preguntas que, aunque complejas, sí permiten imaginar un experimento. Por ejemplo, si quisiéramos estimar el efecto de comenzar la escuela a una edad más avanzada, podríamos imaginar un diseño en el que a algunos niños se les asigna aleatoriamente empezar el primer grado a los seis años, y a otros, a los siete. Luego, compararíamos sus puntajes en pruebas estandarizadas al final del segundo grado. Aun así, este diseño enfrenta un problema: los niños que comienzan más tarde son también más grandes, y la madurez puede explicar parte de las diferencias. Es decir, la edad y la duración de la escolarización quedarían entrelazadas. Incluso con un experimento ideal, algunos efectos son difíciles de aislar completamente.

## Más allá del diseño: relevancia y aporte científico {-}

Además de identificar con claridad la relación causal y el experimento ideal, una buena investigación causal también debe justificar su importancia. Algunas preguntas clave que los investigadores deben hacerse al definir su objeto de estudio son: ¿por qué esta pregunta es relevante o interesante?, ¿por qué la literatura existente no ha resuelto aún esta cuestión?, y ¿cómo contribuye mi trabajo a avanzar esa frontera?

Estas preguntas ayudan a ubicar el proyecto dentro de un marco más amplio, que no solo busca estimar efectos, sino también producir conocimiento útil, replicable y teóricamente informado.

## 🧰 Checklist para una buena pregunta de investigación causal {-}

```{r checklist-pregunta-causal, echo=FALSE, results='asis'}

library(tibble)
library(knitr)
library(kableExtra)

checklist <- tribble(
  ~Pregunta, ~Descripción,

  "¿Cuál es la relación causal de interés?",
  "Define con claridad qué variable actúa como causa y cuál como efecto.",

  "¿Puedes describir el experimento ideal?",
  "Imagina cómo se asignaría aleatoriamente el tratamiento y cómo medirías el impacto.",

  "¿Por qué esta pregunta es importante o interesante?",
  "Justifica la relevancia empírica, social o política del tema.",

  "¿Qué aporta respecto a la literatura existente?",
  "Identifica vacíos o limitaciones en estudios previos que tu trabajo busca superar.",

  "¿Qué mecanismos o teoría motivan la hipótesis causal?",
  "Asegúrate de que haya una narrativa teórica detrás de la relación que estudias."
)

kbl(checklist, align = "l", booktabs = TRUE, caption = "Checklist para formular una buena pregunta de investigación causal") %>%
  kable_styling(full_width = FALSE, position = "center", bootstrap_options = c("striped", "hover"))
```

## Conceptos Importantes {-}

### El Contrafactual {-}

> ¿Cuál habría sido el resultado para los participantes si **no** hubieran participado?

Este concepto es fundamental en la inferencia causal: cada persona tiene un resultado **observado** y un resultado **potencial no observado**. Este último es el contrafactual, es decir, lo que habría ocurrido si la persona hubiera estado en la otra condición (tratada o no tratada).

---

### Visualizando el Contrafactual {-}

Participante (Tratado)
```{r, ninas1, out.width = "20%", echo = FALSE, fig.align='left'}
knitr::include_graphics("img/ninas1.png")
```
$Y_1 \Rightarrow$ Resultado observado

No Participante (Control)
```{r, ninas1c, out.width = "20%", echo = FALSE, fig.align='right'}
knitr::include_graphics("img/ninas1.png")
```
$Y_0 \Rightarrow$ Resultado del contrafactual


### La Banda Sonora {-}

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/playlist/29gLVvN2oYO0p7zB40ts73?utm_source=generator" width="100%" height="352" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

---

### Resultados Potenciales {-}

Cada individuo tiene dos posibles resultados:

- $Y_i(D=0)$: resultado si **no** recibe el tratamiento
- $Y_i(D=1)$: resultado si **recibe** el tratamiento

Pero solo uno de ellos es observable. 

Por ejemplo, Carolina tiene una pierna rota. Tratamiento: $D=0$ No ir al hospital, $D=1$ Ir al hospital

- $Y_i(0)$: si no va al hospital, su pierna **no** se recupera
- $Y_i(1)$: si va al hospital, su pierna **no** se recupera

Ahora veamos a Camila quien también tiene una pierna rota.

- $Y_i(0)$: si no va al hospital, su pierna **no** se recupera
- $Y_i(1)$: si va al hospital, su pierna **se recupera**

Por últimpo está Mónica  quien también tiene una pierna rota.

- $Y_i(0)$: si no va al hospital, su pierna **se recupera**
- $Y_i(1)$: si va al hospital, su pierna **no** se recupera

Pregunta: ¿a cual de las tres le conviene ir al hospital?

### Problema Fundamental de la Inferencia Causal {-}

Nunca podemos observar los **dos** resultados potenciales para un mismo individuo.

Esto genera un problema de datos faltantes: no sabemos cuál habría sido el resultado bajo la condición alternativa.

Solo observamos **uno** de los dos resultados potenciales. Formalmente:

$$
Y_i = \begin{cases}
  Y_i(0) & \text{si } D_i = 0 \\
  Y_i(1) & \text{si } D_i = 1 \\
\end{cases}
$$

donde $D_i$ indica si el individuo fue tratado ($D_i=1$) o no ($D_i=0$).


### Establecer Causalidad (Deseo de Clonación) {-}

En el mundo ideal, podríamos clonar personas para observar ambos resultados. Como esto no es posible, buscamos estimaciones mediante grupos de comparación.

Tratado
```{r, ninas1a, out.width = "20%", echo = FALSE, fig.align='center'}
knitr::include_graphics("img/ninas1.png")
```
$Y_1 \Rightarrow$ Resultado observado


Clon en Control
```{r, ninas1b, out.width = "20%", echo = FALSE, fig.align='center'}
knitr::include_graphics("img/ninas1.png")
```
$Y_0 \Rightarrow$ Resultado contrafactual



[Ver en YouTube](https://youtu.be/iPBV3BlV7jk)

::: {.video-box}

### 🎥 Video recomendado: *Mastering Metrics*

<iframe width="100%" height="315" src="https://www.youtube.com/embed/iPBV3BlV7jk"
title="Mastering Metrics" frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
allowfullscreen></iframe>

:::


## Ceteris Paribus {-}

> *Todos los demás factores permanecen constantes.*

Este principio es la piedra angular del análisis causal. Para estimar el efecto de una intervención o tratamiento, debemos **aislar su impacto** de todas las demás influencias posibles. Idealmente, quisiéramos comparar un mundo donde algo ocurre con uno donde no ocurre, manteniendo todo lo demás constante.

## Establecer Causalidad {-}

- Nunca observamos ambos estados (tratado y no tratado) para el mismo individuo.
- ¿Qué soluciones existen?
  - Buscar una persona similar en todas las características relevantes.
  - Comparar promedios entre grupos tratados y no tratados (⚠️ puede haber *sesgo de selección*).
  - Comparar antes y después en los mismos individuos (⚠️ puede haber *sesgo de maduración*).


## Solución 1: Buscar una persona similar {-}

### **Ceteris Paribus: ¿Perfecto?**

**Tratada**  
```{r, out.width = "20%", echo = FALSE}
knitr::include_graphics("img/ninas1.png")
```

- $Y_1 \Rightarrow$ resultado observado



**Control**  
```{r, ninas3, out.width = "20%", echo = FALSE}
knitr::include_graphics("img/ninas3.png")
```

- $Y_0 \Rightarrow$ resultado del contrafactual


## Efecto Promedio del Tratamiento (ATE) {-}

El **Average Treatment Effect (ATE)** se define como:

\[
ATE = E[\tau] = E[Y_i(D=1) - Y_i(D=0)]
\]

Pero si no podemos observar los dos resultados potenciales para un mismo individuo, tampoco podemos calcular directamente este promedio.


---

## Solución 2: Diferencia de Medias= Efecto Causal + Sesgo de Selección

.pull-left[ **Tratados** 
```{r,  out.width = "20%", echo = F}
include_graphics("img/pegado3.png")
```
]

.pull-right[ **Controles** 
```{r,  out.width = "20%", echo = F}
include_graphics("img/pegado4.png")
```
]

## Solución 2: Diferencia de Medias = Efecto Causal + Sesgo de Selección {-}

Una alternativa común para estimar efectos causales es comparar los promedios de los grupos tratados y no tratados. Sin embargo, esta estrategia suele estar contaminada por **sesgo de selección**: los grupos pueden diferir de manera sistemática en variables que también afectan el resultado.

.pull-left[
**Tratados**  
```{r, out.width = "20%", echo = FALSE}
knitr::include_graphics("img/pegado3.png")
```
]

.pull-right[
**Controles**  
```{r, out.width = "20%", echo = FALSE}
knitr::include_graphics("img/pegado4.png")
```
]

---

## Sesgo de Selección {-}

El **sesgo de selección** ocurre cuando las personas que reciben un tratamiento son inherentemente diferentes de aquellas que no lo reciben. Estas diferencias pueden estar asociadas con los resultados que estamos tratando de medir, incluso si no hubieran recibido el tratamiento.

Incluso con muestras grandes, este problema persiste. Por ejemplo, las personas suelen decidir participar en un programa cuando creen que obtendrán beneficios, lo que significa que sus resultados podrían haber sido distintos desde el principio. En otras palabras, $E[Y_i(D=1) - Y_i(D=0)]$ puede ser mayor para quienes se auto-seleccionan.

---

## Solución 3: Comparaciones Antes-Después = Efecto Causal + Efecto de Maduración {-}

Otra estrategia simple consiste en comparar los resultados antes y después del tratamiento para los mismos individuos. Esta comparación, sin embargo, **asume implícitamente que no hay tendencia temporal** en la variable de interés. Es decir, que cualquier cambio entre el "antes" y el "después" se debe exclusivamente al tratamiento.

Esta suposición es débil, especialmente en contextos donde hay aprendizaje, adaptación o efectos acumulativos en el tiempo.

---

## Comparaciones Prohibidas {-}

En el análisis causal riguroso, debemos ser escépticos de dos comparaciones muy comunes:

- **Tratados vs. Controles** sin aleatorización  
- **Pre-tratamiento vs. Post-tratamiento** sin grupo de comparación  

Ambas requieren supuestos extremadamente fuertes —en muchos casos imposibles de verificar o cumplir en la práctica— para identificar un efecto causal válido.

---

## ¿Y Entonces? {-}

Dada la imposibilidad de observar directamente el contrafactual y los riesgos de comparaciones inadecuadas, ¿cómo podemos avanzar en el análisis causal?

.pull-left[
```{r, simon11, out.width = "60%", echo = FALSE}
knitr::include_graphics("img/simon1.jpeg")
```

.fuente[Fuente: @banrepcultural]
]

---

## ¿Cómo podemos estimar efectos causales? {-}

Hoy en día contamos con un conjunto robusto de herramientas para abordar esta pregunta. Estas técnicas buscan crear **contrafactuales plausibles**, ya sea mediante diseño experimental o estrategias cuasi-experimentales.

**Entre las principales estrategias se encuentran:**

- **Experimentos aleatorizados**: donde los participantes son asignados aleatoriamente al tratamiento y al control.
- **Métodos cuasi-experimentales**, como:
  - Diferencias en diferencias (DiD)
  - Emparejamiento (Matching)
  - Variables instrumentales (IV)
  - Regresión discontinua (RD)
  - Función de control
  - Controles sintéticos
  - Causal Machine Learning

Cada uno de estos métodos tiene fortalezas y limitaciones, y será explorado en detalle a lo largo del libro.





<!--chapter:end:01-intro.Rmd-->


# Stata para Principiantes 

::: {.boxinfo}
Puedes consultar el **Stata Cheat Sheet** completo aquí: [https://geocenter.github.io/StataTraining/pdf/AllCheatSheets.pdf](https://geocenter.github.io/StataTraining/pdf/AllCheatSheets.pdf)
:::

## Macros en Stata {-}

Las **macros** en Stata son herramientas para almacenar texto que luego puede reutilizarse en comandos posteriores. No son variables, no almacenan datos numéricos como tal, sino texto que puede ser evaluado o invocado más adelante. Se usan con frecuencia para simplificar código, automatizar tareas repetitivas, o construir loops.

Stata tiene dos tipos principales de macros:

- `local`: válidas solo dentro del entorno donde se definieron (por ejemplo, dentro de un programa o loop).
- `global`: válidas en todo el entorno de trabajo mientras dure la sesión (desaconsejadas para la mayoría de tareas por riesgo de sobreescritura accidental).

### Macro local: definición y expansión {-}

```stata
local uno 1
display `uno'
```

Esto imprimirá `1` en la consola. La macro `uno` se expande y sustituye por su contenido (`1`) antes de ejecutar el comando.



### Evaluar expresiones dentro de macros {-}

Si queremos que Stata **evalue una expresión**, usamos el signo igual `=` luego del nombre del macro.

```stata
local suma = 2 + 2
display `suma'
```

Stata calcula `2 + 2` y guarda el resultado `4` como texto dentro de `suma`. Al hacer `display`, se imprime el número 4.



### Macro con texto {-}

```stata
local saludo "¡Hola, mundo!"
display "`saludo'"
```

Esto mostrará:

```
¡Hola, mundo!
```

Ojo: cuando una macro contiene texto, siempre encierra su invocación entre comillas para evitar errores de interpretación.



### Macro global: uso y precaución {-}

```stata
global pi 3.1416
display $pi
```

Al usar `global`, la invocación se hace con **signo dólar** (`$`). El contenido se mantiene accesible en toda la sesión.

> ⚠️ Se recomienda evitar nombres obvios en `global`  ya que puede generar conflictos si se reutilizan nombres con comandos establecidos. 



### Scalar vs. Macro {-}

Un **scalar** almacena valores numéricos (reales), no texto. Se usa para cálculos matemáticos, estadísticas o comparaciones numéricas.

```stata
scalar x = 2 + 3
display x
```

Esto imprime `5`.

```stata
scalar area = 3.1416 * (2^2)
display area
```

Resultado:

```
12.5664
```

Diferencia clave:

- `macro`: almacena texto (puede ser número, pero como cadena).
- `scalar`: almacena un número real que puede usarse en operaciones matemáticas.


### Buenas prácticas {-}

- Usa `local` por defecto.
- Usa nombres descriptivos para evitar confusión.
- Cierra comillas cuando el contenido tiene espacios o texto.
- Borra scalars con `scalar drop nombre` si ya no los necesitas.


::: {.boxejercicio}
### 🧩 Ejercicio recomendado  {-}

Crea una macro con tu nombre y otra con tu año de nacimiento. Luego muestra una frase concatenando ambas:

```stata
local nombre "Ana"
local nacimiento 1980
display "Hola, mi nombre es `nombre' y nací en `nacimiento'"
```

:::


::: {.boxnote}
Las macros son esenciales para automatizar análisis en Stata. Úsalas para loops, programación y construcción flexible de comandos.
:::

## Loops en Stata {-}

Los **loops** en Stata permiten automatizar tareas repetitivas, iterando sobre listas de elementos o rangos numéricos. Son muy útiles cuando necesitas aplicar un mismo comando a varias variables, realizar simulaciones o crear múltiples gráficos/tablas de forma eficiente.

### Loop con `foreach` {-}

`foreach` itera sobre una lista de elementos, que pueden ser:

- nombres de variables
- palabras clave
- números, si se combinan con `of numlist`

#### a) Iterar sobre variables específicas  {-}

```stata 
foreach var in mpg price displacement {
    regress `var' weight
}
```

#### b) Iterar sobre nombres arbitrarios  {-}

```stata 
foreach color in rojo azul verde {
    display "El color es `color'"
}
```

#### c) Iterar sobre variables en la base usando `of varlist`  {-}

```stata 
sysuse auto, clear
foreach v of varlist price weight length {
    summarize `v'
}
```

#### d) Iterar sobre subconjuntos: condición y resultado  {-}

```stata 
foreach s of varlist price weight {
    quietly summarize `s' if foreign == 1
    display "Promedio de `s' para foreign = 1: " r(mean)
}
```



### Loop con `forvalues` {-}

`forvalues` itera sobre una **secuencia numérica** definida por un rango o paso.

#### a) Secuencia simple  {-}

```stata
forvalues i = 1/5 {
    display "Iteración `i'"
}
```

#### b) Incrementos diferentes  {-}

```stata
forvalues j = 10(2)20 {
    display "`j'"
}
```

#### c) Anidar loops con `forvalues`  {-}

```stata
forvalues i = 1/3 {
    forvalues j = 1/3 {
        display "Fila: `i', Columna: `j'"
    }
}
```

### Loop con `while` {-}

`while` permite ejecutar código mientras una condición sea verdadera. Es útil para estructuras de control más manuales o condicionales más complejas.

```stata
local i = 1
while `i' <= 5 {
    display "`i'"
    local ++i
}
```


::: {.boxejercicio}
### 🧠 Ejercicios recomendados  {-}

1. Usa `foreach` para crear un gráfico `histogram` para cada una de las siguientes variables: `mpg`, `price`, y `weight`.
2. Usa `forvalues` para crear 10 variables llamadas `x1`, `x2`, ..., `x10` con valores aleatorios entre 0 y 100.
3. Crea un loop anidado que calcule y muestre el producto de cada par `(i, j)` para `i` en 1 a 3 y `j` en 1 a 4.
4. Usa `while` para contar hacia atrás desde 10 hasta 1.
5. En un loop, calcula la media de cada variable numérica del conjunto de datos, pero **solo si su desviación estándar es mayor que 5**.

:::

## Programas definidos por el usuario {-}

En Stata puedes definir tus propios programas usando el comando `program define`. Esto es especialmente útil para empaquetar comandos que usas con frecuencia o para crear rutinas más limpias dentro de proyectos complejos.

### Estructura básica {-}

```stata
program define saludo
    display "Hola, FELIZ día"
end

saludo
```

Este programa se llama `saludo` y simplemente imprime un mensaje. Para ejecutarlo, basta con escribir su nombre.



### Programas con argumentos {-}

Puedes pasar información a un programa con `args` o con `syntax`.

#### a) Con `args`  {-}

```stata
capture program drop cuadrado

program define cuadrado
    args x
    display "El cuadrado de `x' es: " = `x'^2
end

cuadrado 4
```

> Esto imprimirá: `El cuadrado de 4 es: 16`


#### b) Con `syntax` (más power)  {-}

```stata
capture program drop promedio

program define promedio
    syntax varlist(min=1 max=1)
    summarize `varlist'
end

promedio mpg
```

> `syntax` verifica que se cumpla una estructura: aquí, exactamente una variable.



### Tu programa original mejorado: `mysum` {-}

```stata
capture program drop mysum

program define mysum
    syntax varlist(min=1 max=1)
    quietly summarize `varlist'
    display "Variable: `varlist'"
    display "Promedio: " %6.2f r(mean)
    display "Desviación estándar: " %6.2f r(sd)
end

mysum weight
```


### Notas importantes {-}

- Siempre usar `capture program drop nombre` antes de definir uno nuevo.
- Usa `syntax` cuando quieras controlar argumentos y prevenir errores.
- Dentro del programa, puedes acceder a estadísticas almacenadas con `r()`, `e()`, etc.
- Usa `quietly` para ejecutar comandos sin mostrar su salida completa.


::: {.boxejercicio}
### 🔧 Ejercicios recomendados  {-}

1. Crea un programa llamado `saluda` que reciba un nombre y diga "Hola, [nombre]".
2. Crea un programa `promedio_si` que calcule el promedio de una variable solo para observaciones que cumplen una condición (por ejemplo, `foreign == 1`). Usa `args` para pasar la variable.
3. Define un programa llamado `comparar` que reciba dos variables y calcule la diferencia de medias entre ambas (no un `ttest`, solo `mean(var1) - mean(var2)`).
4. Intenta crear un programa con `syntax` que valide que el usuario haya pasado exactamente una variable, y que esta sea numérica. Si no, que dé un mensaje de error.

:::

## Almacenamiento de resultados con `postfile` y loops {-}

Cuando queremos guardar resultados generados dentro de un loop para analizarlos después (por ejemplo, coeficientes, medias, errores estándar), Stata nos ofrece una herramienta poderosa: `postfile`.

### ¿Qué hace `postfile`? {-}

Permite crear una tabla temporal (como una mini base de datos) en la que puedes ir guardando los resultados de cada iteración del loop. Al final, puedes abrirla como si fuera cualquier base.


### Paso a paso: guardar medias con `summarize` {-}

Supongamos que queremos guardar la media y la desviación estándar de varias variables numéricas de forma automatizada.

```stata
sysuse auto, clear

tempname resultados
tempfile archivo

postfile `resultados' str15 variable media sd using `archivo'

foreach var in price weight length {
    quietly summarize `var'
    post `resultados' ("`var'") (r(mean)) (r(sd))
}

postclose `resultados'

use `archivo', clear
list
```


### ¿Qué hicimos aquí? {-}

1. `tempname` crea un alias para el objeto de `postfile`.
2. `tempfile` genera una ruta temporal para almacenar los resultados.
3. `postfile` define las variables a guardar (aquí: nombre, media y desviación estándar).
4. Dentro del loop, usamos `post` para guardar cada fila.
5. Cerramos con `postclose`.
6. Cargamos el archivo resultante con `use` y lo exploramos.


### Buenas prácticas {-}

- Usa `tempfile` para evitar escribir archivos por accidente.
- Usa tipos de datos adecuados: `str` para nombres, `numeric` para estadísticas.
- Siempre cierra el objeto con `postclose` antes de usar el archivo.


::: {.boxejercicio}
### 📦 Ejercicios con `postfile`  {-}

1. Modifica el ejemplo para guardar también el número de observaciones (`r(N)`).
2. Aplica un `regress` en un loop sobre varias variables dependientes y guarda los coeficientes de `weight` en cada una.
3. Crea una base de resultados que incluya, por cada variable, un indicador lógico que diga si su media es mayor a 500.
4. Exporta la base final a Excel usando `export excel`.

:::

## Resumen y buenas prácticas {-}

A lo largo de este capítulo exploramos los componentes fundamentales para comenzar a trabajar eficientemente en Stata. Aprendimos a:

- Usar **macros locales y globales** para automatizar tareas y hacer código más flexible.
- Escribir **loops (`foreach`, `forvalues`, `while`)** para aplicar comandos de forma repetida sin redundancia.
- Definir **programas personalizados** usando `program define`, con argumentos simples (`args`) o controlados (`syntax`).
- Implementar un programa divertido con frases de reguetón, mostrando que también se puede aprender con humor.
- Utilizar **`postfile`** para almacenar resultados generados dentro de loops y analizarlos de manera estructurada.

---

### Buenas prácticas al programar en Stata {-}

✅ Usa `local` en lugar de `global` siempre que sea posible.  
✅ Nombra tus macros y archivos temporales de forma clara y consistente.  
✅ Usa `capture` para evitar errores si un programa ya existe.  
✅ Cierra siempre `postfile` con `postclose` antes de usar el archivo.  
✅ Usa `syntax` dentro de tus programas para validar entradas del usuario.  
✅ No olvides comentar tu código. Facilita su mantenimiento y revisión.  
✅ Cuando sea posible, **grafica** tus resultados. Visualizar patrones es clave.  
✅ Prefiere loops bien documentados a copiar y pegar comandos.

---

::: {.boxejercicio}
### 🧠 Ejercicio de repaso  {-}

Imagina que estás analizando una base de datos de estudiantes. Quieres:

1. Crear un loop que recorra varias variables (como `math_score`, `reading_score`, `attendance`).
2. Para cada variable:
   - Calcular la media y desviación estándar
   - Guardar esos valores con `postfile`
3. Escribir un programa llamado `informe_var` que reciba una variable y muestre un mini informe con:
   - Nombre de la variable
   - Media
   - Desviación estándar
   - Mensaje personalizado si la media es mayor a un umbral dado
4. Ejecutar `informe_var` dentro del loop usando `syntax`

:::

## ¿Y si quiero hacerlo en R o Python? {-}

Aquí les dejo cómo realizar tareas comunes de análisis de datos en **Stata**, **R** y **Python**. Puede servir como guía rápida para quienes están aprendiendo varios lenguajes a la vez o quieren migrar entre ellos.


## 1. Asignar valores y mostrar texto {-}

| Tarea                    | Stata                       | R                                | Python                            |
|-------------------------|-----------------------------|----------------------------------|-----------------------------------|
| Asignar un número       | `scalar x = 5`              | `x <- 5`                         | `x = 5`                           |
| Asignar texto           | `local nombre "Ana"`       | `nombre <- "Ana"`               | `nombre = "Ana"`                 |
| Mostrar texto + var     | `display "Hola `nombre'"   | `cat(paste("Hola", nombre))`     | `print(f"Hola {nombre}")`        |

---

## 2. Operaciones básicas {-}

| Operación            | Stata           | R             | Python         |
|---------------------|------------------|---------------|----------------|
| Suma                | `display 2+2`    | `2 + 2`       | `2 + 2`        |
| Raíz cuadrada       | `display sqrt(4)`| `sqrt(4)`     | `math.sqrt(4)` |
| Valor absoluto      | `abs(-2)`        | `abs(-2)`     | `abs(-2)`      |

> En R necesitas `library()` si usas `sqrt`. En Python, debes importar `import math`.



## 3. Loops básicos {-}

### Iterar sobre lista de variables {-}


**Stata:**
```stata
foreach var in var1 var2 var3 {
    summarize `var'
}
```

**R:**
```r
for (var in c("var1", "var2", "var3")) {
    summary(df[[var]])
}
```

**Python:**
```python
for var in ["var1", "var2", "var3"]:
    print(df[var].describe())
```

---

## 4. Crear funciones/programas {-}

**Stata:**
```stata
program define cuadrado
    args x
    display "Resultado: " = `x'^2
end
cuadrado 4
```

**R:**
```r
cuadrado <- function(x) {
  return(x^2)
}
cuadrado(4)
```

**Python:**
```python
def cuadrado(x):
    return x**2
cuadrado(4)
```

---

## 5. Guardar resultados dentro de un loop {-}

**Stata (con postfile):**
```stata
tempname resultados
tempfile archivo
postfile `resultados' str10 var media using `archivo'
foreach v of varlist x1 x2 x3 {
    quietly summarize `v'
    post `resultados' ("`v'") (r(mean))
}
postclose `resultados'
use `archivo', clear
```

**R:**
```r
resultados <- data.frame(var = character(), media = numeric())
for (v in c("x1", "x2", "x3")) {
  media <- mean(df[[v]], na.rm = TRUE)
  resultados <- rbind(resultados, data.frame(var = v, media = media))
}
```

**Python:**
```python
resultados = []
for v in ["x1", "x2", "x3"]:
    media = df[v].mean()
    resultados.append({"var": v, "media": media})
resultados_df = pd.DataFrame(resultados)
```

## DESCARGA LOS DOCUMENTOS {-}

**Descargar Stata do file**:
[Descargar Stata](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/Clase0_StataBasics/clase0_stata.do)

**Descargar R script**:
[Descargar R](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/Clase0_StataBasics/clase0_R.R)

**Descargar Phyton Notebook**:
[Descargar Phyton](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/Clase0_StataBasics/clase0_phyton.ipynb)

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiazescobar/libro_cortes/blob/main/dofile/Clase0_StataBasics/clase0_phyton.ipynb)

**Descarga los Datos**
[Descargar Datos](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/Clase0_StataBasics/hh_98.dta)





<!--chapter:end:02-StataBasics.Rmd-->

# 📘 Definición de estimadores, resultados potenciales e introducción al sesgo de selección

---
::: {.boxinfo}
## 🎯 Metas de aprendizaje {-}

- Entender qué es un **resultado potencial**  
- Diferenciar entre **ATE**, **ATT**, **ATU** y el **estimador naïve**  
- Comprender la lógica del **sesgo de selección** y su relación con los **contrafactuales**


## 📚 Lecturas recomendadas  {-}

- **Lectura 1:** *The Credibility Revolution* - Angrist y Pischke (2010)  
  [Enlace al artículo](https://www.aeaweb.org/articles?id=10.1257/jep.24.2.3)  
- **Lectura 2:** Bernal y Peña – Capítulo 2  
- **Lectura 3:** Bernal y Peña – Capítulo 3  
:::

### 🔹 Resultados potenciales  {-}

Para cada unidad \( i \), existen dos posibles resultados:

- \( Y_i(D=1) \): resultado si **recibe tratamiento**  
- \( Y_i(D=0) \): resultado si **no recibe tratamiento**

Pero solo observamos uno de ellos:

\[
Y_i = D_i \cdot Y_i(D=1) + (1 - D_i) \cdot Y_i(D=0)
\]

Donde:  
- \( D_i = 1 \) si la unidad fue tratada  
- \( D_i = 0 \) si no fue tratada

---

### 🔹 Parámetros de interés  {-}

#### 📌 Efecto Promedio del Tratamiento (ATE)  {-}

\[
ATE = \mathbb{E}[Y_i(D=1) - Y_i(D=0)]
\]

#### 📌 Efecto Promedio del Tratamiento sobre los Tratados (ATT)  {-}

\[
ATT = \mathbb{E}[Y_i(D=1) - Y_i(D=0) \mid D_i = 1]
\]

#### 📌 Efecto Promedio del Tratamiento sobre los No Tratados (ATU)  {-}

\[
ATU = \mathbb{E}[Y_i(D=1) - Y_i(D=0) \mid D_i = 0]
\]

#### 📌 Estimador naïve (comparación directa de medias)  {-}

\[
\mathbb{E}[Y_i \mid D_i = 1] - \mathbb{E}[Y_i \mid D_i = 0]
\]

---

### 🔹 ¿Por qué no es suficiente el estimador naïve?  {-}

El estimador naïve asume implícitamente que:

\[
\mathbb{E}[Y_i(D=0) \mid D_i = 1] = \mathbb{E}[Y_i(D=0) \mid D_i = 0]
\]

Es decir, que los grupos tratados y no tratados son **comparables** en su resultado contrafactual.  
Este supuesto es **poco realista** si la asignación al tratamiento está relacionada con factores que afectan el resultado, como motivación, ingresos o necesidad.

---

### 🔹 Sesgo de selección  {-}

El **sesgo de selección** se define como la diferencia entre el estimador naïve y el verdadero ATT:

\[
\text{Sesgo} = \left( \mathbb{E}[Y_i(D=1) \mid D_i = 1] - \mathbb{E}[Y_i(D=0) \mid D_i = 1] \right)
- \left( \mathbb{E}[Y_i(D=1) \mid D_i = 1] - \mathbb{E}[Y_i(D=0) \mid D_i = 0] \right)
\]

Lo que se reduce a:

\[
\text{Sesgo} = \mathbb{E}[Y_i(D=0) \mid D_i = 0] - \mathbb{E}[Y_i(D=0) \mid D_i = 1]
\]

> Si los no tratados (controles) tienen peores resultados potenciales que los tratados, el estimador naïve **sobreestima** el verdadero efecto del tratamiento. {-}


::: {.boxejercicio .green title="🧠 Pausa activa: ¿Dónde está el contrafactual?"}

## 🔢 Ejercicio en clase: Resultados potenciales y sesgo de selección {-}

Supongamos que tenemos una muestra de 8 individuos. Algunos recibieron tratamiento (\(D = 1\)) y otros no (\(D = 0\)). Cada persona tiene dos resultados potenciales:

- \(Y(1)\): lo que obtendría si recibe el tratamiento  
- \(Y(0)\): lo que obtendría si no lo recibe

Pero solo observamos **uno** de esos dos valores:  
\[
Y_i = D_i \cdot Y_i(1) + (1 - D_i) \cdot Y_i(0)
\]

Datos

| ID | \(D_i\) | \(Y_i(D=0)\) | \(Y_i(D=1)\) | \(Y_i\)  |
|----|--------|------------|------------|-----|
| 1  | 1      | 10         | 12          | 12  |
| 2  | 0      | 4          | 5         | 4  |
| 3  | 1      | 9          | 10          | 10   |
| 4  | 1      | 10         | 11         | 11  |
| 5  | 0      | 5          | 6          | 5   |
| 6  | 0      | 3          | 2          | 3   |
| 7  | 1      | 12         | 11          | 11   |
| 8  | 0      | 5          | 7          | 5   |
---

*🎯 Preguntas para discutir en grupo*

1. ¿Cuál es el **contrafactual** que NO podemos observar para cada individuo?
2. Calcula el **efecto promedio del tratamiento sobre los tratados (ATT)**.
3. Calcula el **estimador naïve**:  
   \[
   \mathbb{E}[Y \mid D = 1] - \mathbb{E}[Y \mid D = 0]
   \]
4. ¿Cuál es el **sesgo de selección** entre ambos estimadores?
5. Reflexiona: ¿por qué hay sesgo en este ejemplo? ¿Qué supuesto implícito está fallando?

📌 Pista:

Los individuos tratados tienen mejores valores de \(Y(0)\) (lo que habrían obtenido sin tratamiento) que los no tratados.  
¿Es válido entonces comparar directamente los promedios observados entre grupos?

:::


### 🔹 Sesgo en comparaciones antes-después (sin grupo de control) {-}

Una estrategia común es comparar el **resultado promedio antes y después del tratamiento** en el mismo grupo de individuos tratados:

\[
\text{Estimador Antes-Después} = \mathbb{E}[Y_{t=1} \mid D = 1] - \mathbb{E}[Y_{t=0} \mid D = 1]
\]

Este estimador es observable, pero **no necesariamente causal**, porque no tenemos el contrafactual de lo que habría pasado en \( t = 1 \) sin tratamiento.

¿Qué observamos?

- En \( t = 1 \), observamos \( Y(d=1) \): el resultado **con tratamiento**  
- En \( t = 0 \), observamos \( Y(d=0) \): el resultado **sin tratamiento**

Para identificar el efecto del tratamiento, lo que quisiéramos conocer es:

\[
Y(d=0) \text{ en } t = 1
\]

Es decir, **¿qué habría pasado en el periodo \( t=1 \) si no hubiéramos tratado a nadie?** 💡 El efecto causal real para una unidad sería:

\[
Y(d=1) - Y(d=0) \text{ en el mismo periodo } t=1
\]

Pero en el diseño antes-después usamos \( Y(d=0) \) del periodo anterior como sustituto de ese contrafactual. Entonces, el sesgo es:

\[
\text{Sesgo} = \underbrace{\mathbb{E}[Y(d=0) \text{ en } t = 1]}_{\text{contrafactual deseado}} - \underbrace{\mathbb{E}[Y(d=0) \text{ en } t = 0]}_{\text{valor observado como "antes"}}
\]

Este sesgo aparece si el resultado habría cambiado con el tiempo incluso sin el tratamiento.

🧪 Ejemplo ilustrativo

| Año  | Resultado observado | Tratamiento |
|------|---------------------|-------------|
|2019  | 6                   | 0 (antes)   |
|2020  | 9                   | 1 (después) |

- Estimador antes-después:  
  \[
  9 - 6 = 3
  \]
- Pero supongamos que, sin tratamiento, el resultado en 2020 habría sido 8  
  \[
  \Rightarrow Y(d=0) \text{ en } 2020 = 8
  \]
- Entonces el efecto causal verdadero es:  
  \[
  9 - 8 = 1
  \]
- Y el sesgo de selección por tiempo es:
  \[
  3 - 1 = 2
  \]



El diseño antes-después asume que no habría cambio en el tiempo sin tratamiento. Este supuesto es **muy fuerte** y raramente cierto. Por eso, necesitamos un grupo de control que nos ayude a estimar \( \mathbb{E}[Y(d=0) \text{ en } t=1] \).

> En otras palabras, sin grupo de control **no podemos saber si el cambio fue por el tratamiento o por el tiempo**.

::: {.boxvideo .green title="🎥 Videos recomendados:"}


Estos videos ayudan a reforzar visualmente los conceptos de **resultados potenciales**, **contrafactuales** y **sesgo en el diseño antes-después**.


<iframe width="100%" height="315" src="https://www.youtube.com/embed/ln5LBKiF8hE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<iframe width="100%" height="315" src="https://www.youtube.com/embed/iPBV3BlV7jk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

:::




---

::: {.boxnote }

🛠️ 💬 **PROMPT DE CHATGPT PARA REFLEXIÓN PROFUNDA**

Estás escribiendo el apartado metodológico de un artículo donde se implementa un programa de formación técnica para jóvenes. Tu grupo de tratamiento incluye individuos que aplicaron y fueron aceptados. No tienes grupo de control explícito, pero tienes datos de resultados antes y después.

📌 Instrucciones:

Escribe a ChatGPT usando el siguiente mensaje:

Actúa como mi tutor metodológico. No quiero que simplemente expliques los conceptos, sino que me hagas preguntas, desafíes mis supuestos, y me ayudes a razonar paso a paso como si estuviéramos en una asesoría.

🧪 Contexto: Quiero evaluar el efecto de un programa de formación técnica para jóvenes. Tengo datos de ingreso mensual antes y después del programa, pero solo para quienes participaron. Estoy pensando en calcular:

    Ȳ_despues - Ȳ_antes

para reportar el efecto del programa.

Quiero que me ayudes a pensar críticamente si esta estrategia identifica un efecto causal. Por favor:

1. Guíame para identificar cuál es el verdadero contrafactual que estoy ignorando.
2. Pregúntame qué estoy asumiendo implícitamente.
3. Explórame en qué condiciones este estimador funcionaría bien.
4. Hazme reflexionar sobre qué sesgos podrían surgir si los ingresos hubieran aumentado igual sin el programa.
5. Llévame a conectar este ejemplo con los conceptos de Y(D=1), Y(D=0), ATT, ATE y el estimador naïve.

⚠️ Importante: no me lo des todo resuelto. Quiero que me vayas preguntando cosas, como haría un buen profe. Quiero pensar, no solo escuchar. Hazlo interactivo.
:::



---


<!--chapter:end:03-Parametros.Rmd-->

# Estimadores Causales en Secciones Transversales 

::: {.boxinfo}
## 📚 Lecturas obligatorias{-}

- Lectura 4 – Capítulo 4 del libro de Scott Cunningham:  
  👉 [Mixtape: Potential Outcomes](https://mixtape.scunning.com/04-potential_outcomes)

- Documento de referencia sobre RCT:  
  📄 `RCT.pdf`
:::

*🎯 Objetivo de la clase* 

Aprenderemos a estimar y comparar distintos **estimadores del efecto causal**:

- ATE (Efecto Promedio en la Población)
- ATT (Efecto Promedio en los Tratados)
- ATU (Efecto Promedio en los No Tratados)
- Estimador Naïve (diferencia observada entre grupos)

Repasamos conceptos de la clase anterior: resultados potenciales, estimadores de media y regresión simple.


---

*📥 Cargar la base y generar la variable de resultado observado* 

```stata
use "04_data.dta", clear

* Generamos el resultado observado según el tratamiento recibido
gen y = D*yd1 + (1-D)*yd0

label var y "Salarios en millones de pesos"
label define D 0 "Control" 1 "Tratados"
label value D D
numlabel, add
```

---

*📊 Estadísticas descriptivas por grupo*

```stata
tab D

          D |      Freq.     Percent        Cum.
------------+-----------------------------------
 0. Control |          4       50.00       50.00
1. Tratados |          4       50.00      100.00
------------+-----------------------------------
      Total |          8      100.00
      
      
sum y

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
           y |          8       7.625    3.700869          3         12


bysort D: sum y
------------------------------------------------------------------------------------------
-> D = 0. Control

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
           y |          4        4.25    .9574271          3          5

------------------------------------------------------------------------------------------
-> D = 1. Tratados

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
           y |          4          11    .8164966         10         12

sum y if D == 0

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
           y |          4        4.25    .9574271          3          5

sum y if D == 1

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
           y |          4          11    .8164966         10         12

```

Nos permite observar las diferencias **promedio** entre grupos tratados y de control.

---

 *📎 Diferencia de medias*

```stata
ttest y, by(D)

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. err.   Std. dev.   [95% conf. interval]
---------+--------------------------------------------------------------------
0. Contr |       4        4.25    .4787136    .9574271     2.72652     5.77348
1. Trata |       4          11    .4082483    .8164966    9.700772    12.29923
---------+--------------------------------------------------------------------
Combined |       8       7.625    1.308455    3.700869    4.530996      10.719
---------+--------------------------------------------------------------------
    diff |               -6.75    .6291529               -8.289482   -5.210518
------------------------------------------------------------------------------
    diff = mean(0. Contr) - mean(1. Trata)                        t = -10.7287
H0: diff = 0                                     Degrees of freedom =        6

    Ha: diff < 0                 Ha: diff != 0                 Ha: diff > 0
 Pr(T < t) = 0.0000         Pr(|T| > |t|) = 0.0000          Pr(T > t) = 1.0000

reg y D, robust
```

*📎 Regresioón Simple*
Modelo:
\[ Y = \alpha + \tau D + \varepsilon \]

- \( \tau \) representa el estimador naïve (diferencia de medias observada).
- No es causal si hay **sesgo de selección**.


```stata
Linear regression                               Number of obs     =          8
                                                F(1, 6)           =     115.11
                                                Prob > F          =     0.0000
                                                R-squared         =     0.9505
                                                Root MSE          =     .88976

------------------------------------------------------------------------------
             |               Robust
           y | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
           D |       6.75   .6291529    10.73   0.000     5.210518    8.289482
       _cons |       4.25   .4787136     8.88   0.000      3.07863     5.42137
------------------------------------------------------------------------------
```
---

*🧮 Estimación de ATE, ATT y ATU*

```stata
gen tau = yd1 - yd0   // efecto individual
display "ATE: "
sum tau
scalar ATE = r(mean)
di "ATE = " ATE

sum tau if D == 1
scalar ATT = r(mean)
di "ATT = " ATT

sum tau if D == 0
scalar ATU = r(mean)
di "ATU = " ATU
```

---

*🧯 Comparación con el estimador naïve*

```stata
sum y if D==1
scalar ybar_1 = r(mean)

sum y if D==0
scalar ybar_0 = r(mean)

scalar NAIVE = ybar_1 - ybar_0
di "Naive = " NAIVE

di "Sesgo de selección = " NAIVE - ATT
```


*⚙️ Programa para estimadores*

```stata
cap prog drop estimadores
program define estimadores
    args tau y D

    di "--- Calculando estimadores ---"
    quietly {
        sum `tau'
        scalar ATE = r(mean)
        sum `tau' if `D' == 1
        scalar ATT = r(mean)
        sum `tau' if `D' == 0
        scalar ATU = r(mean)
        sum `y' if `D' == 1
        scalar ybar_1 = r(mean)
        sum `y' if `D' == 0
        scalar ybar_0 = r(mean)
        scalar NAIVE = ybar_1 - ybar_0
    }
    di "ATE = " ATE
    di "ATT = " ATT
    di "ATU = " ATU
    di "Naive = " NAIVE
    di "Sesgo de Selección = " NAIVE - ATT
end

* Llamamos el programa:
estimadores tau y D
```



*🧪 Experimento 1: ¿Qué pasa si aumento el tamaño muestral? *

```stata
drop y tau
expand 10000

* Generar nuevamente el resultado
gen y = D*yd1 + (1-D)*yd0
gen tau = yd1 - yd0

estimadores tau y D
```

🔍 **Moraleja:** Aumentar el tamaño no elimina el sesgo si hay selección.

---

*🧪 Experimento 2: Asignación aleatoria *

```stata
drop y D tau
set seed 87634
gen D = (uniform() > 0.5)
gen y = D*yd1 + (1-D)*yd0

* Repetimos estimadores
gen tau = yd1 - yd0

estimadores tau y D
...
```

🎯 Con asignación aleatoria:
\[ ATE \approx ATT \approx ATU \approx Naïve \]


---

*🧠 Reflexiones finales*

- El estimador naïve es solo válido si hay **asignación aleatoria**.
- La diferencia entre ATT y Naïve nos permite cuantificar el **sesgo de selección**.
- El ATE no es igual al ATT si hay **heterogeneidad en el tratamiento**.
- El tamaño muestral no soluciona problemas de sesgo.

---

## 📎 Descargas {-}

**Descargar Stata do file**:  
[Descargar Stata](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/04_ParametrosStata/04_stata.do)

**Descargar R script**:  
[Descargar R](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile//04_ParametrosStata/04_R.R)

**Descargar Phyton Notebook**:  
[Descargar Phyton](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile//04_ParametrosStata/04_phyton.ipynb)

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiazescobar/libro_cortes/blob/main/dofile//04_ParametrosStata/04_phyton.ipynb)

**Descarga los Datos**:  
[Descargar Datos](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/Clase4_Estimadores/04_data.dta)

```

🔍 **Moraleja:** Aumentar el tamaño no elimina el sesgo si hay selección.

---

*🧪 Experimento 2: Asignación aleatoria *

```stata
drop y D tau
set seed 87634
gen D = (uniform() > 0.5)
gen y = D*yd1 + (1-D)*yd0

* Repetimos estimadores
gen tau = yd1 - yd0
sum tau
scalar ATE = r(mean)
...
```

🎯 Con asignación aleatoria:
\[ ATE \approx ATT \approx ATU \approx Naïve \]


---

*🧠 Reflexiones finales*

- El estimador naïve es solo válido si hay **asignación aleatoria**.
- La diferencia entre ATT y Naïve nos permite cuantificar el **sesgo de selección**.
- El ATE no es igual al ATT si hay **heterogeneidad en el tratamiento**.
- El tamaño muestral no soluciona problemas de sesgo.

---

## 📎 Descargas {-}

**Descargar Stata do file**:  
[Descargar Stata](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/04_ParametrosStata/04_stata.do)

**Descargar R script**:  
[Descargar R](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/04_ParametrosStata/04_R.R)

**Descargar Phyton Notebook**:  
[Descargar Phyton](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/04_ParametrosStata/04_phyton.ipynb)

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiazescobar/libro_cortes/blob/main/dofile/04_ParametrosStata/04_phyton.ipynb)

**Descarga los Datos**:  
[Descargar Datos](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/04_ParametrosStata/04_data.dta)

<!--chapter:end:04-ParametrosStata.Rmd-->

# ¿Por qué la asignación aleatoria elimina el sesgo?

::: {.boxinfo}
**🎯 Objetivo del capítulo**

- ✔️ Entender qué se debe cumplir para que un experimento sea exitoso y reduzca el sesgo de selección  
- ✔️ Conocer las diferentes formas de realizar asignación aleatoria  
- ✔️ Traducir los resultados potenciales a una regresión lineal  

### 📚 Lecturas{-}

- 📄 **Paper Alert:** [When Should You Adjust Standard Errors for Clustering? (NBER)](https://www.nber.org/papers/w24003)
- 📄 **Teoría:** [Lectura 4. Capítulo 4 Bernal y Peña (PDF)](https://www.dropbox.com/s/vxpgxt22pvphwx3/Capitulo%204%20Bernal%20y%20Pe%C3%B1a.pdf?dl=0)

:::

Tenemos el siguiente modelo de regresión lineal:

\[
Y = \alpha + \tau D + \varepsilon
\]

Donde:

- \( Y \) es el resultado (por ejemplo, salario),
- \( D \) es una variable binaria de tratamiento,
- \( \varepsilon \) incluye **motivación**, que no observamos.


Supongamos que la verdadera relación es:

\[
Y = \alpha + \tau D + \gamma M + u
\]

Donde:

- \( M \) es motivación (no observable),
- \( u \) es un nuevo error sin correlación con \( D \),
- Pero **no incluimos** \( M \) en la estimación → queda absorbido en \( \varepsilon = \gamma M + u \)

El modelo estimado es:

\[
Y = \alpha + \tau D + \varepsilon \quad \text{con} \quad \varepsilon = \gamma M + u
\]


Recordemos que el estimador de mínimos cuadrados ordinarios es:

\[
\hat{\beta} = (X'X)^{-1} X'Y
\]

Con \( X = [\mathbf{1}, D] \), tenemos:

\[
\hat{\beta} = 
\begin{bmatrix}
\hat{\alpha} \\
\hat{\tau}
\end{bmatrix}
=
\left( \begin{bmatrix}
1 & D_1 \\
\vdots & \vdots \\
1 & D_n \\
\end{bmatrix}' 
\begin{bmatrix}
1 & D_1 \\
\vdots & \vdots \\
1 & D_n \\
\end{bmatrix} \right)^{-1}
\begin{bmatrix}
1 & D_1 \\
\vdots & \vdots \\
1 & D_n \\
\end{bmatrix}' Y
\]

Queremos analizar el **sesgo** en \(\hat{\tau}\). Sustituyendo \( Y = \alpha + \tau D + \gamma M + u \)

Entonces:

\[
\hat{\tau} = \tau + \gamma \cdot \frac{\text{Cov}(D, M)}{\text{Var}(D)}
\]

Interpretación

- Si \( \text{Cov}(D, M) \neq 0 \), es decir, **si el tratamiento está correlacionado con la motivación**, el estimador de \(\tau\) estará **sesgado**.
- El sesgo es proporcional a:
  - El efecto de la motivación sobre \( Y \): \( \gamma \)
  - La correlación entre \( D \) y \( M \): \( \text{Cov}(D, M) \)


**Resumen del sesgo**

::: {.table .table-bordered .table-striped}
| Correlación entre \( D \) y \( M \) | Efecto de \( M \) sobre \( Y \) (\( \gamma \)) | ¿Hay sesgo en \( \hat{\tau} \)? | Dirección esperada del sesgo      |
|:----------------------------------:|:---------------------------------------------:|:-------------------------------:|:---------------------------------:|
| Cero                               | Cualquiera                                     | ❌ No                           | –                                 |
| Positiva                           | Positiva                                       | ✅ Sí                          | \( \hat{\tau} > \tau \) (sesgo hacia arriba) |
| Positiva                           | Negativa                                       | ✅ Sí                          | \( \hat{\tau} < \tau \) (sesgo hacia abajo) |
| Negativa                           | Positiva                                       | ✅ Sí                          | \( \hat{\tau} < \tau \) (sesgo hacia abajo) |
| Negativa                           | Negativa                                       | ✅ Sí                          | \( \hat{\tau} > \tau \) (sesgo hacia arriba) |
:::

**Lectura de la tabla**:

- Si el tratamiento está **correlacionado positivamente** con la motivación y la motivación **aumenta** el resultado, el estimador de \( \tau \) estará **sesgado hacia arriba**.
- Si la motivación está **omitida** y además está **correlacionada con el tratamiento**, siempre hay **sesgo**.
- Solo si la **motivación no está correlacionada con el tratamiento**, aunque no la observemos, **no hay sesgo**.


## ¿Qué hace la aleatorización?{-}
📌 La **aleatorización** garantiza \( \text{Cov}(D, M) = 0 \), eliminando el sesgo de selección sin necesidad de observar \( M \).

 *Visualización: motivación, selección y aleatorización*

```{r, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)
library(ggplot2)
library(patchwork)

# Simular datos
N <- 1000
motivacion <- rnorm(N)
epsilon <- rnorm(N)
salario <- 10 + 3 * motivacion + epsilon

# Tratamiento con sesgo: más motivados
tratamiento_sesgado <- ifelse(motivacion > 0, 1, 0)
# Tratamiento aleatorio
tratamiento_azar <- rbinom(N, 1, 0.5)

# Armar data frame
df <- data.frame(
  salario,
  motivacion,
  sesgado = factor(tratamiento_sesgado, labels = c("Control", "Tratado")),
  azar = factor(tratamiento_azar, labels = c("Control", "Tratado"))
)

# Gráfico 1: dispersión con auto-selección
p1 <- ggplot(df, aes(x = motivacion, y = salario, color = sesgado)) +
  geom_point(alpha = 0.4) +
  labs(title = "Auto-selección: motivación no balanceada",
       color = "Grupo (sesgado)") +
  theme_minimal()

# Gráfico 2: dispersión con aleatorización
p2 <- ggplot(df, aes(x = motivacion, y = salario, color = azar)) +
  geom_point(alpha = 0.4) +
  labs(title = "Aleatorización: motivación balanceada",
       color = "Grupo (azar)") +
  theme_minimal()

p1 + p2
```

---

## Densidad de la motivación por grupo {-}

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Gráfico 3: densidad de motivación según tratamiento sesgado
dens1 <- ggplot(df, aes(x = motivacion, fill = sesgado)) +
  geom_density(alpha = 0.5) +
  labs(title = "Distribución de motivación (auto-selección)",
       fill = "Grupo (sesgado)") +
  theme_minimal()

# Gráfico 4: densidad de motivación según tratamiento aleatorio
dens2 <- ggplot(df, aes(x = motivacion, fill = azar)) +
  geom_density(alpha = 0.5) +
  labs(title = "Distribución de motivación (aleatorización)",
       fill = "Grupo (azar)") +
  theme_minimal()

dens1 + dens2
```


Por lo tanto ya no es necesario observar la motivación, ya que la aleatorización garantiza que los grupos sean comparables. Y la estimación de  \(\tau\) será insesgada y consistente en la siguiente regresión: 

\[
Y = \alpha + \tau D + u
\]

- Cual es el valor de \(\alpha\) y \(\tau\) en este caso?
- ¿Por qué se incluyen controles en el análisis de RCT?
- ¿Qué pasa si no se incluyen?
- ¿Calcule los errores estándar? 



::: {.boxvideo .green title="🎥 Videos recomendados:"}


- [Video 1](https://www.youtube.com/embed/eGRd8jBdNYg)  
- [Video 2](https://www.youtube.com/embed/crpuBZv6XtA)  
- [Video 3](https://www.youtube.com/embed/xlX3VtuIfQ0)

Y todos los que encuentres en Google buscando: **RCT Esther Duflo**
:::


::: {.boxnote }

🛠️ 💬 **PROMPT DE CHATGPT PARA REFLEXIÓN PROFUNDA**

**Instrucciones**: Copia este mensaje en ChatGPT o la IA de tu preferencia. Tu objetivo no es obtener respuestas, sino **reflexionar guiado por preguntas**.

---

Hola. Actúa como mi tutor metodológico. No quiero que me des respuestas. Quiero que me ayudes a pensar como si estuviéramos en una tutoría.

Estoy estudiando diseños experimentales. Entiendo que si el tratamiento se asigna aleatoriamente, entonces \( \text{Cov}(D, X) = 0 \), incluso para variables no observables.

Pero sigo viendo que en muchos papers experimentales incluyen **controles en la regresión**. Ayúdame a pensar **paso a paso** si eso es necesario o no.

Por favor, hazme preguntas como:

- ¿Qué gana o pierde la estimación si incluyo controles?
- ¿Qué pasa si hay desequilibrios por azar?
- ¿Qué efecto tiene sobre la precisión del estimador?
- ¿Los controles ayudan a mejorar algo aunque \( \hat{\tau} \) ya sea insesgado?
- ¿Hay casos en que incluir controles puede ser problemático?

⚠️ No me des respuestas. Solo nuevas preguntas que me ayuden a entender mejor este punto.

:::


---

<!--chapter:end:05-RCT.Rmd-->

# Experimentos Controlados RECETA

::: {.boxinfo}
**🎯 Metas de aprendizaje**

- Entender cómo hacer **inferencia estadística** con asignación aleatoria.  
- Discutir **cuándo** incluir controles y **qué ocurre** con la varianza/SE al incluirlos.  
- Traducir **resultados potenciales** a una **regresión lineal**.  
- Implementar **diagnósticos de balance**, **efectos heterogéneos** y **reporte reproducible**.

## 📚 Lecturas {-}

- **Paper Alert:** [When Should You Adjust Standard Errors for Clustering? (NBER w24003)](https://www.nber.org/papers/w24003)  
- **Teoría:** [Jakiela & Ozier — Handout](http://economics.ozier.com/econ626/lec/econ626-L07-handout-2019.pdf)  
- **Herramienta:** [J-PAL — Power calculations](https://www.povertyactionlab.org/resource/power-calculations)
:::




*1) Setup*

- Unidades: \(N\).
- Tratamiento: \(D_i \in \{0,1\}\). Asignado de manera aleatoria.
- Resultados potenciales: \(Y_i(D=1),\, Y_i(D=0)\).
- Resultado observado:
  \[
  Y_i \;=\; D_i\,Y_i(D=1) \;+\; (1-D_i)\,Y_i(D=0).
  \]
- Tamaños de muestra:
  - Tratados: \(N_1 = \sum_i \mathbb{1}\{D_i=1\}\).
  - Control: \(N_0 = \sum_i \mathbb{1}\{D_i=0\}\).

 *2) Supuestos*

1. **Asignación aleatoria:** cada unidad \(i\) es asignada de manera independiente al tratamiento con probabilidad \(p\).
   \[
   D_i \;\perp\; \{Y_i(1), Y_i(0)\}.
   \]
2. **SUTVA** (Stable Unit Treatment Value Assumption): no hay interferencia entre unidades ni versiones del tratamiento.  
   En español: no hay externalidades ni efectos de equilibrio general que cambien los resultados potenciales de otros individuos.

*3) Implicaciones y parámetros*

- **ATE (efecto promedio):**
  \[
  \tau \;=\; \mathbb{E}\!\left[\,Y(D=1)-Y(D=0)\,\right].
  \]
- **Identificación con aleatorización:**
  \[
  \mathbb{E}[\,Y \mid D=1\,] - \mathbb{E}[\,Y \mid D=0\,] \;=\; \tau.
  \]
- **Estimador por diferencia de medias:**
  \[
  \hat{\tau} \;=\; \bar{Y}_{D=1}-\bar{Y}_{D=0}.
  \]
- **Estimador “naïve” sin aleatorización (descomposición):**
  \[
  \underbrace{\mathbb{E}[Y \mid D=1] - \mathbb{E}[Y \mid D=0]}_{\text{naïve}}
  \;=\;
  \underbrace{\tau}_{\text{efecto causal}}
  \;+\;
  \underbrace{\mathbb{E}[Y(0)\mid D=1] - \mathbb{E}[Y(0)\mid D=0]}_{\text{sesgo de selección}}.
  \]


## Paso a Paso para un RCT {-}

### PASO 1) Diseñar el experimento {-}
- Definir la **población objetivo** y el **tratamiento**.
- Determinar el **tamaño de muestra** necesario para detectar un efecto significativo (usando `power` en Stata/R).


### Paso 2) Aleatorizar la asignación (Stata) {-}

Abajo tienes varias formas de asignar tratamiento en Stata. Incluyo opciones con `runiform()` (base) y con el comando de SSC `randtreat` (estratificado, proporciones desiguales, clusters y manejo de *misfits*).

> **Regla de oro:** fija una semilla reproducible y *guárdala* en el log/notas del proyecto.
```stata
* Reproducibilidad
set seed 20250813
local RNGSTATE = c(rngstate)   // guardar estado; opcionalmente escríbelo en tu log
display as text "Seed guardada: `RNGSTATE'"
```

*Bernoulli simple (50/50) con `runiform()`*

Asigna tratamiento con probabilidad 0.5 a cada unidad.

```stata
* Supón que tienes un id por fila
sort id
gen double u = runiform()
gen byte D = (u < 0.5)           // 1=tratado, 0=control
tab D
drop u
```

**Cambio de proporción (p=0.30):**

```stata
gen double u = runiform()
gen byte D = (u < 0.30)
tab D
drop u
```

**Asignación con conteo exacto de tratados (p.ej., 40% exacto)**

Asegura exactamente `round(N*0.40)` tratados.

```stata
count
local N      = r(N)
local Ntr    = round(`N'*0.40)   // número exacto de tratados
gen double u = runiform()
sort u
gen byte D   = (_n <= `Ntr')
tab D
drop u
```

**Estratificada** (bloques) con `runiform()`

Mantén la proporción deseada **dentro de cada estrato** (ej., por `mujer` × `programa`).

> Con `round()` obtienes conteo **exacto por estrato**; globalmente puede variar levemente si los tamaños de estrato son impares.

```stata
egen long strata = group(mujer programa), label
bys strata: gen double u = runiform()
bys strata (u): gen byte D = (_n <= round(_N*0.50))   // 50/50 exacto en cada estrato
tab D
by strata: tab D
drop u
```

**Proporción distinta por estrato (p.ej., 40%):**

```stata
bys strata: gen double u = runiform()
bys strata (u): gen byte D = (_n <= round(_N*0.40))
by strata: tab D
drop u
```

**Cluster** (aleatoriza a nivel del cluster y la pasa a individuos)

Ej.: clusters en `escuela`.

```stata
* Una fila por cluster
preserve
keep escuela
duplicates drop

gen double u = runiform()
sort u
* 50% de escuelas tratadas
count
local C = r(N)
local Ctr = round(`C'*0.50)
gen byte D_cluster = (_n <= `Ctr')
tempfile cl
save `cl', replace
restore

* Trae la asignación al nivel individual
merge m:1 escuela using `cl', keep(match master) nogen
gen byte D = D_cluster
tab D
```

Usando **`randtreat`** (SSC): multi-brazos, proporciones desiguales, estratos y *misfits*

**Instalación**

```stata
ssc install randtreat, replace
```

**Binario 50/50 (sin estratos)**

```stata
randtreat, generate(D) multiple(2) setseed(20250813)
tab D
```

**Binario 50/50 dentro de estratos (`mujer` × `programa`)**

```stata
randtreat, generate(D) multiple(2) strata(mujer programa) setseed(20250813)
by mujer programa: tab D
```

** Proporciones desiguales (30% tratado, 70% control)**

```stata
randtreat, generate(D) multiple(2) unequal(0.30 0.70) setseed(20250813)
tab D
```

** Multi-brazo (T1/T2/C = 0.4/0.4/0.2) con estratos**

```stata
randtreat, generate(arm) multiple(3) unequal(0.40 0.40 0.20) ///
    strata(mujer programa) setseed(20250813)
tab arm
by mujer programa: tab arm
```

**Manejo de *misfits***
Cuando el tamaño de estrato no es divisible por los brazos/proporciones, usa `misfits()`:

* `misfits(strata)` o `misfits(wstrata)`: resuelve dentro de cada estrato (ponderado o no).
* `misfits(global)` o `misfits(wglobal)`: resuelve a nivel global priorizando las proporciones totales.
* `misfits(missing)`: deja *misfits* sin asignar para que los decidas manualmente.

```stata
randtreat, generate(arm) multiple(3) unequal(0.40 0.40 0.20) ///
    strata(mujer programa) misfits(wstrata) setseed(20250813)
```

**Forzar número exacto de tratados totales** (binario)

> Útil si necesitas exactamente `N_t` tratados (no solo proporción).

```stata
* Por ejemplo, exactamente 50 tratados en total:
randtreat, generate(D) multiple(2) ntreated(50) setseed(20250813)
tab D
```

**Cluster + `randtreat`**
Ejecuta `randtreat` sobre los **clusters únicos** y luego une a individuos.

```stata
preserve
keep escuela mujer programa
duplicates drop

* 2 brazos 50/50 por estratos de escuela (y opcionalmente otras):
randtreat, generate(Dcl) multiple(2) strata(mujer programa) setseed(20250813)
tempfile cl
save `cl', replace
restore

merge m:1 escuela using `cl', nogen
gen byte D = Dcl
tab D
```

### PASO 3) Verificar el balance de covariables {-}


```stata
use "data.dta", clear

* Tratamiento 1=B, 0=A
gen D = (grupo == "B")
label define Dlbl 0 "Control" 1 "Tratado"
label values D Dlbl

* Outcome y y controles
gen y        = resultado
gen mujer    = (genero == "Mujer")
gen pregrado = (programa == "Pregrado")
gen maestria = (programa == "Maestría")

global X edad mujer libros pregrado maestria
```
* Programa de diferencia de medias con t-test y opción de guardar resultados en un archivo .dta**

1. **Pruebas univariadas (t‐tests):** comparar medias de cada covariable \(X\) entre \(D=1\) y \(D=0\).  
   Objetivo: **no rechazar** que las medias son iguales.
2. **Prueba conjunta (F‐test):** regresión de \(D\) sobre \(X\) (LPM) y test conjunto de significancia de \(X\).
3. **Modelos binarios:** `logit/probit` de \(D\) sobre \(X\); evaluar razón de verosimilitud o \(\chi^2\) conjunta.
4. **Si se rechaza balance:** revisar procedimiento (bloqueos/estratos, reasignación, control por \(X\) pretratamiento en la estimación).

```stata
cap program drop difmedias
program define difmedias, rclass
    version 18
    syntax varlist(min=1) [, BY(varname) SAVEPOST(string asis)]
    if ("`by'"=="") {
        di as err "Necesitas especificar , by(varname)."
        exit 198
    }
    local vars `varlist'

    local do_post = 0
    if ("`savepost'"!="") local do_post = 1
    tempname posth
    if `do_post' {
        postfile `posth' str32 variable ///
            double mean_T mean_C diff tstat pval se sd_T sd_C N_T N_C ///
            using "`savepost'", replace
    }

    di as txt "Var{col 22}Mean_T{col 33}Mean_C{col 44}Diff{col 55}t{col 66}p"
    foreach v of local vars {
        qui ttest `v', by(`by')

        local mu1 = r(mu_1)
        local mu2 = r(mu_2)
        local sd1 = r(sd_1)
        local sd2 = r(sd_2)
        local N1  = r(N_1)
        local N2  = r(N_2)
        local t   = r(t)
        local se  = r(se)
        local p   = r(p)

        local mean_T = `mu2'
        local mean_C = `mu1'
        local diff   = `mu2' - `mu1'

        di as res "`v'" "{col 22}" %9.3f `mean_T' "{col 33}" %9.3f `mean_C' "{col 44}" %9.3f `diff' "{col 55}" %9.3f `t' "{col 66}" %9.3f `p'

        if `do_post' {
            post `posth' ("`v'") (`mean_T') (`mean_C') (`diff') (`t') (`p') (`se') (`sd2') (`sd1') (`N2') (`N1')
        }
    }
    if `do_post' postclose `posth'
end


* Balance de X
difmedias $X, by(D) savepost("Table_Balance_raw.dta")

use "Table_Balance_raw.dta", clear
order variable mean_T mean_C diff tstat pval se sd_T sd_C N_T N_C
export excel using "Table_Balance_raw.xlsx", firstrow(variables) replace

* ALTERNATIVAS 
cap which iebaltab
if _rc ssc install ietoolkit, replace

iebaltab $X, grpvar(D) control(0) rowvarlabels ftest ///
     savexlsx("Table_Balance.xlsx") replace format(%9.3f)

eststo clear
eststo: reg   D $X, vce(robust)
test $X
eststo: logit D $X, vce(robust)
eststo: probit D $X, vce(robust)

esttab, se star(* 0.10 ** 0.05 *** 0.01) ///
    stats(N r2, fmt(%9.0g %9.3f) labels("N" "R2")) ///
    nomtitle compress

```

### PASO 4) Estimar el efecto del tratamiento {-}

\[
Y_i \;=\; \alpha \;+\; \tau D_i \;+\; \varepsilon_i.
\]
- Bajo aleatorización, \(\hat{\tau}_{OLS}\) es insesgado y coincide con la diferencia de medias.

Sea \(D\) la columna binaria (0/1) y \(\iota\) el vector de unos. Entonces, en \(Y = \alpha \iota + \tau D + \varepsilon\), se tiene:
\[
\hat{\tau}
\;=\;
\bar{Y}_1 - \bar{Y}_0.
\]

```stata
eststo clear
eststo m1: reg y D, vce(robust)
eststo m2: reg y D $X, vce(robust)

esttab m1 m2, se star(* 0.10 ** 0.05 *** 0.01) ///
    stats(N r2, fmt(%9.0g %9.3f) labels("N" "R2")) ///
    b(%9.4f) compress nonote ///
    title("Efecto del tratamiento con y sin controles")
```


::: {.boxnote}
Interpretación según escala de \(Y\)

1. **\(Y\) en niveles (continuo):** \(\hat{\tau}\) es diferencia de unidades de \(Y\) entre tratados y control.
2. **\(Y\) en logaritmos:** \(\hat{\tau}\) es una **semi-elasticidad**; el efecto porcentual aproximado es \(100\times \hat{\tau}\%\).  
   Efecto exacto: \(100\times(\exp(\hat{\tau})-1)\%\).  
   *Ejemplo:* \(\hat{\tau}=0.13 \Rightarrow \exp(0.13)-1 \approx 0.139\) → **13.9%**.
3. **\(Y\) estandarizado:** media 0 y varianza 1; \(\hat{\tau}\) se interpreta en **desviaciones estándar**.
4. **\(Y\) binario:** \(\hat{\tau}\) es **diferencia de probabilidades** (puntos porcentuales).  
   *Ejemplo:* \(p_1=0.30\), \(p_0=0.25\) ⇒ \(\hat{\tau}=0.05 = 5\) pp.
:::




## Inferencia estadística {-}

###  Asignación a nivel individual (dos muestras independientes) {-}
- **Varianza del estimador (clásica):**
  \[
  \operatorname{Var}(\hat{\tau})
  \;\approx\;
  \frac{S_1^2}{N_1} \;+\; \frac{S_0^2}{N_0},
  \]
  donde \(S_1^2\) y \(S_0^2\) son las varianzas muestrales por grupo.
- **Heterocedasticidad:** usar **SE robustas** (HC).  
- **Asignación por clusters:** usar **SE cluster** al nivel de asignación. Con pocos clusters, considerar **wild cluster bootstrap**.

### Pruebas {-}
- **Significancia individual:** \(H_0:\,\tau=0\) (t‐test).  
- **Significancia conjunta de \(X\):** en \(D \sim X\), \(H_0:\,\beta_X=0\) (F/\(\chi^2\)). Queremos **no rechazar**.

## ¿Cuándo incluir controles? {-}

- **Identificación:** con aleatorización correcta, **no necesitas** \(X\) para identificar \(\tau\).
- **Precisión:** incluir \(X\) **pretratamiento** que **expliquen \(Y\)** puede **reducir** \(\operatorname{Var}(\hat{\tau})\) (menor varianza residual).  
  Si \(X\) es irrelevante o colineal, puede **aumentar** la SE de \(\hat{\tau}\).
- **Modelo con controles:**
  \[
  Y_i \;=\; \alpha + \tau D_i + X_i'\beta + u_i.
  \]
  Si \(X \perp D\) (por diseño) y \(X\) explica \(Y\), esperar **SE(D)** más pequeñas.

## Efectos heterogéneos (HET) {-}

- **Especificación general:**
  \[
  Y_i \;=\; \alpha \;+\; \tau D_i \;+\; \gamma W_i \;+\; \delta\, (D_i \times W_i) \;+\; X_i'\beta \;+\; u_i,
  \]
  donde \(W\) es el moderador (p. ej., **mujer**, **libros**, **cuartiles de edad**).
- **Interpretación:** \(\delta\) es el **cambio en el efecto de \(D\)** al pasar de un nivel de \(W\) a otro.  
  Usar `margins`/`marginsplot` para reportar efectos marginales y perfiles por subgrupo.

```stata
* Por mujer (binaria)
eststo clear
eststo: reg y D##i.mujer, vce(robust)
margins, dydx(D)
margins D, at(mujer=(0 1))

* Por libros (continua)
eststo: reg y D##c.libros, vce(robust)
margins, dydx(D) at(libros=(0(1)8))
marginsplot, title("Efecto marginal de D según libros")
graph export "margins_libros.pdf", replace

* Por cuartiles de edad
xtile q_edad = edad, nq(4)
eststo: reg y D##i.q_edad, vce(robust)
margins D#q_edad
marginsplot, title("Heterogeneidad por cuartiles de edad")
graph export "margins_qedad.pdf", replace

```


::: {.boxejercicio}
**🧪 Ejercicios**

1. **Aleatorización (Bernoulli y estratos)**
   (a) Con tu `data.dta`, genera `D` con p=0.5 usando `runiform()`.
   (b) Repite p=0.3.
   (c) Crea estratos por `mujer × programa` y asigna 50/50 exacto por estrato.

2. **`randtreat` avanzado**
   (a) Asigna 3 brazos (T1/T2/C) con proporciones 0.4/0.4/0.2 y estratos `mujer × programa`.
   (b) Resuelve *misfits* con `misfits(wstrata)` y reporta conteos por estrato.

3. **Balance**
   (a) Corre `difmedias $X, by(D)` y exporta a `Table_Balance_raw.xlsx`.
   (b) Estima `D ~ X` (LPM/logit/probit) y reporta el test conjunto.
   (c) Interpreta: ¿hay evidencia de desbalance?

4. **Efecto del tratamiento**
   (a) Estima $Y\sim D$ y $Y\sim D+X$ con SE robustas.
   (b) Compara $\hat\tau$ y sus SE entre modelos; discute precisión.
   (c) Si `resultado` es binario, interpreta en puntos porcentuales.

5. **Heterogeneidad**
   (a) Estima $Y\sim D\times \text{mujer}$ y reporta `margins`.
   (b) Estima $Y\sim D\times \text{libros}$, grafica `marginsplot` y comenta el perfil.

**Bonus (opcional):**
6\. Repite la estimación con **SE cluster** suponiendo que la asignación fue por `escuela`. Discute diferencias con SE robustas.
\
:::


## DESCARGA LOS DOCUMENTOS {-}

**Descargar Stata do file**:  
[Descargar Stata](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/Clase1_Experimentos/clase1_stata.do)

**Descargar R script**:  
[Descargar R](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/Clase1_Experimentos/clase1_R.R)

**Descargar Phyton Notebook**:  
[Descargar Phyton](https://raw.githubusercontent.com/adiazescobar/libro_cortes/main/dofile/Clase1_Experimentos/clase1_phyton.ipynb)

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiazescobar/libro_cortes/blob/main/dofile/Clase1_Experimentos/clase1_phyton.ipynb)

**Descarga los Datos**  
*(En esta clase usamos la base real `data.dta` con columnas: `id, resultado, grupo, edad, genero, programa, libros`.)*

<!--chapter:end:06-RCT2.Rmd-->

